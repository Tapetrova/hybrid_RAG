#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–≤: —Å–∫–æ—Ä–æ—Å—Ç—å, —Å—Ç–æ–∏–º–æ—Å—Ç—å, –∫–∞—á–µ—Å—Ç–≤–æ, trade-offs
"""

import json
import numpy as np
from datetime import datetime

class ComprehensiveAnalysis:
    def __init__(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã 100 –≤–æ–ø—Ä–æ—Å–æ–≤
        with open('eval_200_results_20250821_013826.json', 'r') as f:
            self.results = json.load(f)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã hallucination
        with open('hallucination_100_results_20250821_113921.json', 'r') as f:
            self.hall_data = json.load(f)
        
        # –¶–µ–Ω—ã OpenAI (gpt-4o-mini)
        self.gpt_price_per_1k_input = 0.00015  # $0.15 per 1M
        self.gpt_price_per_1k_output = 0.0006   # $0.60 per 1M
        
        # –¶–µ–Ω—ã Tavily API
        self.tavily_price_per_search = 0.001  # ~$1 per 1000 searches
    
    def analyze_performance_metrics(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∂–¥–æ–≥–æ –º–µ—Ç–æ–¥–∞"""
        
        metrics = {
            'base_llm': {
                'avg_response_time': [],
                'context_size': [],
                'api_calls': {'openai': 1, 'tavily': 0},
                'estimated_cost': []
            },
            'vector_rag': {
                'avg_response_time': [],
                'context_size': [],
                'api_calls': {'openai': 1, 'tavily': 1},
                'estimated_cost': []
            },
            'graph_rag': {
                'avg_response_time': [],
                'context_size': [],
                'api_calls': {'openai': 1, 'tavily': 1},
                'estimated_cost': []
            },
            'hybrid_ahs': {
                'avg_response_time': [],
                'context_size': [],
                'api_calls': {'openai': 1, 'tavily': 2},
                'estimated_cost': []
            }
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
        for q in self.results[:100]:  # –ü–µ—Ä–≤—ã–µ 100 –≤–æ–ø—Ä–æ—Å–æ–≤
            for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
                if mode in q:
                    mode_data = q[mode]
                    
                    # –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                    context_size = mode_data.get('context_size', 0)
                    metrics[mode]['context_size'].append(context_size)
                    
                    # –û—Ü–µ–Ω–∫–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏
                    input_tokens = len(q['question_text']) / 4 + context_size / 4  # –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ
                    output_tokens = len(mode_data.get('answer', '')) / 4
                    
                    openai_cost = (input_tokens * self.gpt_price_per_1k_input + 
                                  output_tokens * self.gpt_price_per_1k_output) / 1000
                    
                    tavily_cost = metrics[mode]['api_calls']['tavily'] * self.tavily_price_per_search
                    
                    total_cost = openai_cost + tavily_cost
                    metrics[mode]['estimated_cost'].append(total_cost)
        
        return metrics
    
    def analyze_quality_vs_cost(self):
        """–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–æ vs —Å—Ç–æ–∏–º–æ—Å—Ç—å"""
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ hallucination –∏–∑ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        hall_metrics = {}
        for result in self.hall_data['results']:
            for mode, data in result['metrics'].items():
                if mode not in hall_metrics:
                    hall_metrics[mode] = {'HR': [], 'supported': []}
                hall_metrics[mode]['HR'].append(data['HR'])
                if data['total_claims'] > 0:
                    hall_metrics[mode]['supported'].append(data['supported'] / data['total_claims'])
        
        # –°—Ä–µ–¥–Ω–∏–µ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏
        avg_metrics = {}
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            avg_metrics[mode] = {
                'avg_HR': np.mean(hall_metrics[mode]['HR']),
                'avg_support': np.mean(hall_metrics[mode]['supported'])
            }
        
        return avg_metrics
    
    def analyze_category_performance(self):
        """–ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤–æ–ø—Ä–æ—Å–æ–≤"""
        
        category_performance = {}
        
        for result in self.hall_data['results']:
            category = result['category']
            if category not in category_performance:
                category_performance[category] = {
                    'base_llm': [], 'vector_rag': [], 
                    'graph_rag': [], 'hybrid_ahs': []
                }
            
            for mode, data in result['metrics'].items():
                category_performance[category][mode].append(data['HR'])
        
        # –°—Ä–µ–¥–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        avg_by_category = {}
        for cat, modes in category_performance.items():
            avg_by_category[cat] = {}
            for mode, hrs in modes.items():
                avg_by_category[cat][mode] = np.mean(hrs) if hrs else 0
        
        return avg_by_category
    
    def print_comprehensive_report(self):
        """–í—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç"""
        
        print("="*80)
        print("üìä –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –ú–ï–¢–û–î–û–í RETRIEVAL")
        print("="*80)
        
        # 1. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        perf_metrics = self.analyze_performance_metrics()
        
        print("\nüöÄ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ò –°–¢–û–ò–ú–û–°–¢–¨:")
        print("-"*60)
        
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            avg_context = np.mean(perf_metrics[mode]['context_size']) if perf_metrics[mode]['context_size'] else 0
            avg_cost = np.mean(perf_metrics[mode]['estimated_cost']) if perf_metrics[mode]['estimated_cost'] else 0
            
            print(f"\n{mode.upper()}:")
            print(f"  API –≤—ã–∑–æ–≤—ã: OpenAI={perf_metrics[mode]['api_calls']['openai']}, "
                  f"Tavily={perf_metrics[mode]['api_calls']['tavily']}")
            print(f"  –°—Ä–µ–¥–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {avg_context:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"  –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å/–≤–æ–ø—Ä–æ—Å: ${avg_cost:.5f}")
            print(f"  –°—Ç–æ–∏–º–æ—Å—Ç—å –Ω–∞ 1000 –≤–æ–ø—Ä–æ—Å–æ–≤: ${avg_cost*1000:.2f}")
        
        # 2. –ö–∞—á–µ—Å—Ç–≤–æ vs –°—Ç–æ–∏–º–æ—Å—Ç—å
        quality_metrics = self.analyze_quality_vs_cost()
        
        print("\nüíé –ö–ê–ß–ï–°–¢–í–û vs –°–¢–û–ò–ú–û–°–¢–¨:")
        print("-"*60)
        
        # –í—ã—á–∏—Å–ª—è–µ–º efficiency score
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            avg_cost = np.mean(perf_metrics[mode]['estimated_cost'])
            hr = quality_metrics[mode]['avg_HR']
            support = quality_metrics[mode]['avg_support']
            
            # Efficiency = –∫–∞—á–µ—Å—Ç–≤–æ / —Å—Ç–æ–∏–º–æ—Å—Ç—å (—á–µ–º –≤—ã—à–µ support –∏ –Ω–∏–∂–µ cost, —Ç–µ–º –ª—É—á—à–µ)
            if avg_cost > 0:
                efficiency = support / (avg_cost * 100)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            else:
                efficiency = support
            
            print(f"\n{mode.upper()}:")
            print(f"  Hallucination Rate: {hr:.1%}")
            print(f"  Support Rate: {support:.1%}")
            print(f"  Cost per question: ${avg_cost:.5f}")
            print(f"  Efficiency Score: {efficiency:.2f}")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        cat_perf = self.analyze_category_performance()
        
        print("\nüéØ –°–ü–ï–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        print("-"*60)
        
        for category, modes in cat_perf.items():
            print(f"\n{category.upper()}:")
            best_mode = min(modes, key=modes.get)
            print(f"  –õ—É—á—à–∏–π –º–µ—Ç–æ–¥: {best_mode} (HR={modes[best_mode]:.1%})")
            
            # –ì–¥–µ hybrid_ahs –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ
            if modes['hybrid_ahs'] < modes['vector_rag']:
                improvement = (modes['vector_rag'] - modes['hybrid_ahs']) / modes['vector_rag'] * 100
                print(f"  ‚úÖ Hybrid –ª—É—á—à–µ Vector RAG –Ω–∞ {improvement:.0f}%")
        
        # 4. –ü–æ—á–µ–º—É Hybrid AHS –∏–º–µ–µ—Ç —Å–º—ã—Å–ª
        print("\nüîÑ –ü–†–ï–ò–ú–£–©–ï–°–¢–í–ê HYBRID_AHS:")
        print("-"*60)
        
        # –ê–Ω–∞–ª–∏–∑ –≥–¥–µ hybrid –ª—É—á—à–µ
        hybrid_wins = 0
        vector_wins = 0
        graph_wins = 0
        
        for result in self.hall_data['results']:
            metrics = result['metrics']
            if 'hybrid_ahs' in metrics and 'vector_rag' in metrics:
                if metrics['hybrid_ahs']['HR'] < metrics['vector_rag']['HR']:
                    hybrid_wins += 1
                else:
                    vector_wins += 1
            
            if 'hybrid_ahs' in metrics and 'graph_rag' in metrics:
                if metrics['hybrid_ahs']['HR'] < metrics['graph_rag']['HR']:
                    graph_wins += 1
        
        print(f"\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ–±–µ–¥ (–∏–∑ 100 –≤–æ–ø—Ä–æ—Å–æ–≤):")
        print(f"  Hybrid –ª—É—á—à–µ Vector RAG: {hybrid_wins} —Ä–∞–∑")
        print(f"  Hybrid –ª—É—á—à–µ Graph RAG: {graph_wins} —Ä–∞–∑")
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞
        print(f"\nüí° –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ Hybrid AHS:")
        print("  1. –ê–¥–∞–ø—Ç–∏–≤–Ω–æ—Å—Ç—å –∫ —Ç–∏–ø—É –≤–æ–ø—Ä–æ—Å–∞ (causal vs factual)")
        print("  2. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ—Ç —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –æ–±–æ–∏—Ö –ø–æ–¥—Ö–æ–¥–æ–≤")
        print("  3. –ë–æ–ª–µ–µ —Ä–æ–±–∞—Å—Ç–Ω—ã–π –∫ —Ä–∞–∑–Ω—ã–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        print("  4. –õ—É—á—à–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (2 –∏—Å—Ç–æ—á–Ω–∏–∫–∞)")
        
        # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –í–´–ë–û–†–£ –ú–ï–¢–û–î–ê:")
        print("-"*60)
        
        print("\n1. –î–õ–Ø –ú–ò–ù–ò–ú–ê–õ–¨–ù–û–ô –°–¢–û–ò–ú–û–°–¢–ò:")
        print("   ‚Üí base_llm (–Ω–æ HR=62.3%)")
        
        print("\n2. –î–õ–Ø –õ–£–ß–®–ï–ì–û –ö–ê–ß–ï–°–¢–í–ê:")
        print("   ‚Üí vector_rag (HR=17.6%, –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å)")
        
        print("\n3. –î–õ–Ø CAUSAL/DIAGNOSTIC –í–û–ü–†–û–°–û–í:")
        print("   ‚Üí graph_rag –∏–ª–∏ hybrid_ahs")
        
        print("\n4. –î–õ–Ø PRODUCTION –° –†–ê–ó–ù–´–ú–ò –¢–ò–ü–ê–ú–ò:")
        print("   ‚Üí hybrid_ahs (—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å, —Ä–æ–±–∞—Å—Ç–Ω–æ—Å—Ç—å)")
        
        print("\n5. –î–õ–Ø –ö–†–ò–¢–ò–ß–ù–´–• –ü–†–ò–õ–û–ñ–ï–ù–ò–ô:")
        print("   ‚Üí –ê–Ω—Å–∞–º–±–ª—å vector_rag + –ø—Ä–æ–≤–µ—Ä–∫–∞ base_llm")
        
        # 6. Trade-offs —Ç–∞–±–ª–∏—Ü–∞
        print("\nüìä TRADE-OFFS –ú–ê–¢–†–ò–¶–ê:")
        print("-"*60)
        print("\n–ú–µ—Ç–æ–¥        | –ö–∞—á–µ—Å—Ç–≤–æ | –°—Ç–æ–∏–º–æ—Å—Ç—å | –°–∫–æ—Ä–æ—Å—Ç—å | –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å")
        print("-------------|----------|-----------|----------|----------------")
        print("base_llm     |    ‚ùå    |     ‚úÖ    |    ‚úÖ    |       ‚≠ê")
        print("vector_rag   |    ‚úÖ    |     ‚≠ê    |    ‚≠ê    |       ‚≠ê‚≠ê")
        print("graph_rag    |    ‚≠ê    |     ‚≠ê    |    ‚≠ê    |       ‚≠ê")
        print("hybrid_ahs   |   ‚≠ê‚≠ê   |     ‚ùå    |    ‚ùå    |      ‚≠ê‚≠ê‚≠ê")
        
        print("\n‚úÖ = –æ—Ç–ª–∏—á–Ω–æ, ‚≠ê = —Ö–æ—Ä–æ—à–æ, ‚ùå = –ø–ª–æ—Ö–æ")

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑...")
    analyzer = ComprehensiveAnalysis()
    analyzer.print_comprehensive_report()
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    perf = analyzer.analyze_performance_metrics()
    quality = analyzer.analyze_quality_vs_cost()
    categories = analyzer.analyze_category_performance()
    
    report = {
        'timestamp': datetime.now().isoformat(),
        'performance_metrics': perf,
        'quality_metrics': quality,
        'category_specialization': categories
    }
    
    with open('comprehensive_analysis_report.json', 'w') as f:
        json.dump(report, f, indent=2, default=str)
    
    print("\nüíæ –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ comprehensive_analysis_report.json")

if __name__ == "__main__":
    main()