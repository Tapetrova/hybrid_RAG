#!/usr/bin/env python3
"""
–û—Ü–µ–Ω–∫–∞ –ø–µ—Ä–≤—ã—Ö 200 –†–ï–ê–õ–¨–ù–´–• –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ apqc_auto.json
–í—Å–µ–º–∏ 4 –º–µ—Ç–æ–¥–∞–º–∏ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
"""

import json
import os
import time
import requests
from openai import OpenAI
from dotenv import load_dotenv
from datetime import datetime
import traceback

load_dotenv()

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
OPENAI_KEY = os.getenv('OPENAI_API_KEY')
TAVILY_KEY = "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"

class Eval200Questions:
    def __init__(self):
        self.client = OpenAI(api_key=OPENAI_KEY)
        self.start_time = datetime.now()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        with open('../data/apqc_auto.json', 'r') as f:
            self.dataset = json.load(f)
        
        print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω –¥–∞—Ç–∞—Å–µ—Ç: {len(self.dataset['questions'])} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # –§–∞–π–ª –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.output_file = f"eval_200_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        self.checkpoint_file = "eval_200_checkpoint.json"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º checkpoint –µ—Å–ª–∏ –µ—Å—Ç—å
        self.results = []
        self.processed_ids = set()
        if os.path.exists(self.checkpoint_file):
            with open(self.checkpoint_file, 'r') as f:
                checkpoint = json.load(f)
                self.results = checkpoint.get('results', [])
                self.processed_ids = set(checkpoint.get('processed_ids', []))
                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω checkpoint: —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(self.processed_ids)} –≤–æ–ø—Ä–æ—Å–æ–≤")
    
    def save_checkpoint(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        checkpoint = {
            'results': self.results,
            'processed_ids': list(self.processed_ids),
            'timestamp': datetime.now().isoformat()
        }
        with open(self.checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)
    
    def get_tavily_context(self, query: str, search_type: str = "basic") -> list:
        """–ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Tavily API"""
        
        url = "https://api.tavily.com/search"
        
        # –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
        if search_type == "causal":
            query = f"why cause reason {query}"
        elif search_type == "diagnostic":
            query = f"diagnose troubleshoot symptoms {query}"
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∑–∞–ø—Ä–æ—Å–∞
        query = query[:200]
        
        payload = {
            "api_key": TAVILY_KEY,
            "query": f"automotive {query}",
            "search_depth": "basic",
            "max_results": 2,
            "include_domains": ["mechanics.stackexchange.com", "reddit.com/r/MechanicAdvice"]
        }
        
        try:
            response = requests.post(url, json=payload, timeout=10)
            if response.status_code == 200:
                results = response.json().get('results', [])
                contexts = []
                for r in results:
                    contexts.append({
                        'text': r.get('content', '')[:300],
                        'url': r.get('url', ''),
                        'score': r.get('score', 0.5)
                    })
                return contexts
        except Exception as e:
            print(f"      ‚ö†Ô∏è Tavily error: {e}")
        
        return []
    
    def test_base_llm(self, question: str) -> dict:
        """MODE 1: –ß–∏—Å—Ç—ã–π LLM –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an automotive expert. Answer concisely."},
                    {"role": "user", "content": question}
                ],
                temperature=0,
                max_tokens=200
            )
            
            return {
                "mode": "base_llm",
                "answer": response.choices[0].message.content,
                "context_used": None,
                "context_size": 0,
                "success": True
            }
        except Exception as e:
            print(f"      ‚ùå Error in base_llm: {e}")
            return {
                "mode": "base_llm",
                "answer": f"Error: {str(e)}",
                "context_used": None,
                "context_size": 0,
                "success": False
            }
    
    def test_vector_rag(self, question: str) -> dict:
        """MODE 2: –í–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ + LLM"""
        try:
            contexts = self.get_tavily_context(question, "basic")
            
            if not contexts:
                contexts = []
                context_str = "No additional context available."
            else:
                context_str = "\n".join([c['text'] for c in contexts])
            
            prompt = f"""Context from search:
{context_str}

Question: {question}
Answer based on context:"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Answer based on the provided context."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            return {
                "mode": "vector_rag",
                "answer": response.choices[0].message.content,
                "context_used": contexts,
                "context_size": len(context_str),
                "success": True
            }
        except Exception as e:
            print(f"      ‚ùå Error in vector_rag: {e}")
            return {
                "mode": "vector_rag",
                "answer": f"Error: {str(e)}",
                "context_used": [],
                "context_size": 0,
                "success": False
            }
    
    def test_graph_rag(self, question: str, category: str) -> dict:
        """MODE 3: –ì—Ä–∞—Ñ–æ–≤—ã–π –ø–æ–∏—Å–∫ —Å —É—á—ë—Ç–æ–º —Å–≤—è–∑–µ–π"""
        try:
            contexts = self.get_tavily_context(
                question, 
                "causal" if category in ["causal", "diagnostic"] else "basic"
            )
            
            if not contexts:
                contexts = []
                context_str = "No graph relationships found."
            else:
                context_str = "\n".join([c['text'] for c in contexts])
            
            prompt = f"""Causal/relational context:
{context_str}

Question: {question}
Focus on cause-effect relationships:"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Focus on causal relationships and connections."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            return {
                "mode": "graph_rag",
                "answer": response.choices[0].message.content,
                "context_used": contexts,
                "context_size": len(context_str),
                "success": True
            }
        except Exception as e:
            print(f"      ‚ùå Error in graph_rag: {e}")
            return {
                "mode": "graph_rag",
                "answer": f"Error: {str(e)}",
                "context_used": [],
                "context_size": 0,
                "success": False
            }
    
    def test_hybrid_ahs(self, question: str, category: str) -> dict:
        """MODE 4: –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º"""
        try:
            # –î–≤–∞ —Ç–∏–ø–∞ –ø–æ–∏—Å–∫–∞
            vector_contexts = self.get_tavily_context(question, "basic")
            time.sleep(0.5)  # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
            graph_contexts = self.get_tavily_context(question, "causal")
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã
            if category in ["causal", "diagnostic"]:
                contexts = graph_contexts[:2] + vector_contexts[:1]
            else:
                contexts = vector_contexts[:2] + graph_contexts[:1]
            
            contexts = [c for c in contexts if c]
            
            if not contexts:
                contexts = []
                context_str = "No hybrid context available."
            else:
                context_str = "\n".join([c['text'] for c in contexts])
            
            prompt = f"""Combined vector and graph context:
{context_str}

Question: {question}
Comprehensive answer using all information:"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Provide comprehensive answer using all context."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200
            )
            
            return {
                "mode": "hybrid_ahs",
                "answer": response.choices[0].message.content,
                "context_used": contexts,
                "context_size": len(context_str),
                "success": True
            }
        except Exception as e:
            print(f"      ‚ùå Error in hybrid_ahs: {e}")
            return {
                "mode": "hybrid_ahs",
                "answer": f"Error: {str(e)}",
                "context_used": [],
                "context_size": 0,
                "success": False
            }
    
    def process_question(self, q_data: dict, index: int, total: int) -> dict:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–¥–∏–Ω –≤–æ–ø—Ä–æ—Å –≤—Å–µ–º–∏ –º–µ—Ç–æ–¥–∞–º–∏"""
        
        q_id = q_data['id']
        question = q_data['question']
        category = q_data['category']
        gold_answer = q_data['answer']
        
        print(f"\nüìù –í–æ–ø—Ä–æ—Å {index}/{total} (ID: {q_id})")
        print(f"   –í–æ–ø—Ä–æ—Å: {question[:80]}...")
        print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
        
        result = {
            "question_id": q_id,
            "question_text": question,
            "category": category,
            "gold_answer": gold_answer,
            "context": q_data.get('context', ''),
            "metadata": q_data.get('metadata', {}),
            "timestamp": datetime.now().isoformat()
        }
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤—Å–µ 4 –º–µ—Ç–æ–¥–∞
        print("   ü§ñ base_llm...", end="")
        result["base_llm"] = self.test_base_llm(question)
        print(" ‚úì")
        
        print("   üìä vector_rag...", end="")
        result["vector_rag"] = self.test_vector_rag(question)
        print(" ‚úì")
        
        print("   üï∏Ô∏è graph_rag...", end="")
        result["graph_rag"] = self.test_graph_rag(question, category)
        print(" ‚úì")
        
        print("   üîÑ hybrid_ahs...", end="")
        result["hybrid_ahs"] = self.test_hybrid_ahs(question, category)
        print(" ‚úì")
        
        return result
    
    def run_evaluation(self, limit: int = 200):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É –Ω–∞ –ø–µ—Ä–≤—ã—Ö N –≤–æ–ø—Ä–æ—Å–∞—Ö"""
        
        print("="*80)
        print(f"–û–¶–ï–ù–ö–ê –ü–ï–†–í–´–• {limit} –í–û–ü–†–û–°–û–í –ò–ó –î–ê–¢–ê–°–ï–¢–ê")
        print("="*80)
        
        questions_to_process = []
        for q in self.dataset['questions'][:limit]:
            if q['id'] not in self.processed_ids:
                questions_to_process.append(q)
        
        print(f"\nüìä –ö –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(questions_to_process)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        print(f"‚è≠Ô∏è –£–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(self.processed_ids)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        for i, q_data in enumerate(questions_to_process, 1):
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–æ–ø—Ä–æ—Å
                result = self.process_question(
                    q_data, 
                    len(self.processed_ids) + 1, 
                    limit
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                self.results.append(result)
                self.processed_ids.add(q_data['id'])
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º checkpoint –∫–∞–∂–¥—ã–µ 5 –≤–æ–ø—Ä–æ—Å–æ–≤
                if len(self.results) % 5 == 0:
                    self.save_checkpoint()
                    print(f"   üíæ Checkpoint —Å–æ—Ö—Ä–∞–Ω—ë–Ω ({len(self.results)} –≤–æ–ø—Ä–æ—Å–æ–≤)")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
                if len(self.results) % 10 == 0:
                    elapsed = (datetime.now() - self.start_time).total_seconds()
                    avg_time = elapsed / len(self.results)
                    remaining = (limit - len(self.results)) * avg_time
                    print(f"\n‚è±Ô∏è –ü—Ä–æ–≥—Ä–µ—Å—Å: {len(self.results)}/{limit}")
                    print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –≤–æ–ø—Ä–æ—Å: {avg_time:.1f} —Å–µ–∫")
                    print(f"   –û—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ: {remaining/60:.1f} –º–∏–Ω")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –≤–æ–ø—Ä–æ—Å–∞–º–∏ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
                time.sleep(1)
                
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞ {q_data['id']}: {e}")
                print(traceback.format_exc())
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.save_final_results()
    
    def save_final_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        
        # –ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = self.calculate_statistics()
        stats_file = self.output_file.replace('.json', '_stats.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        print("\n" + "="*80)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–•–†–ê–ù–ï–ù–´")
        print("="*80)
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {len(self.results)}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {self.output_file}")
        print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats_file}")
        print(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è: {(datetime.now() - self.start_time).total_seconds()/60:.1f} –º–∏–Ω—É—Ç")
    
    def calculate_statistics(self) -> dict:
        """–í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        
        stats = {
            "total_questions": len(self.results),
            "timestamp": datetime.now().isoformat(),
            "by_category": {},
            "by_mode": {
                "base_llm": {"success": 0, "errors": 0, "avg_length": 0},
                "vector_rag": {"success": 0, "errors": 0, "avg_context": 0},
                "graph_rag": {"success": 0, "errors": 0, "avg_context": 0},
                "hybrid_ahs": {"success": 0, "errors": 0, "avg_context": 0}
            }
        }
        
        # –ü–æ–¥—Å—á—ë—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for r in self.results:
            cat = r['category']
            if cat not in stats['by_category']:
                stats['by_category'][cat] = 0
            stats['by_category'][cat] += 1
            
            # –ü–æ–¥—Å—á—ë—Ç –ø–æ —Ä–µ–∂–∏–º–∞–º
            for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
                if mode in r:
                    if r[mode].get('success', False):
                        stats['by_mode'][mode]['success'] += 1
                    else:
                        stats['by_mode'][mode]['errors'] += 1
        
        return stats

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ –ø–µ—Ä–≤—ã—Ö 100 –≤–æ–ø—Ä–æ—Å–æ–≤ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
    print("‚ö†Ô∏è –≠—Ç–æ –∑–∞–π–º—ë—Ç –ø—Ä–∏–º–µ—Ä–Ω–æ 20-30 –º–∏–Ω—É—Ç")
    
    evaluator = Eval200Questions()
    evaluator.run_evaluation(limit=100)
    
    print("\n‚úÖ –ì–û–¢–û–í–û!")

if __name__ == "__main__":
    main()