#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑ hallucination –º–µ—Ç—Ä–∏–∫ –Ω–∞ –ü–û–õ–ù–û–ú –¥–∞—Ç–∞—Å–µ—Ç–µ –∏–∑ 706 –≤–æ–ø—Ä–æ—Å–æ–≤
"""

import json
import numpy as np
from datetime import datetime
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()

class FullDatasetHallucinationAnalyzer:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ 706 –≤–æ–ø—Ä–æ—Å–æ–≤...")
        with open('eval_FULL_706_results_20250821_110500.json', 'r') as f:
            data = json.load(f)
            # –§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –Ω–∞–ø—Ä—è–º—É—é
            if isinstance(data, list):
                self.full_results = {'results': data}
            else:
                self.full_results = data
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.full_results['results'])} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        self.hallucination_metrics = []
        self.claims_cache = {}
    
    def extract_claims(self, answer_text: str, q_id: str, mode: str) -> list:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞"""
        
        cache_key = f"{q_id}_{mode}"
        if cache_key in self.claims_cache:
            return self.claims_cache[cache_key]
        
        if not answer_text or len(answer_text) < 10:
            return []
        
        prompt = f"""Extract 3-5 key factual claims from this automotive answer.
Each claim should be a specific, verifiable statement.

Answer: {answer_text[:500]}

Return JSON: {{"claims": [{{"text": "specific claim"}}]}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Extract verifiable claims from automotive answers."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=200,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            claims = result.get('claims', [])
            self.claims_cache[cache_key] = claims[:5]
            return claims[:5]
            
        except Exception as e:
            return []
    
    def judge_claim(self, claim: str, gold_answer: str, context: list, mode: str) -> str:
        """–û—Ü–µ–Ω–∏–≤–∞–µ–º —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ"""
        
        if mode == 'base_llm':
            # –î–ª—è base_llm –ø—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–õ–¨–ö–û –ø–æ –∑–æ–ª–æ—Ç–æ–º—É –æ—Ç–≤–µ—Ç—É
            prompt = f"""Judge if this claim is supported by the reference answer.

Claim: {claim}
Reference Answer: {gold_answer[:500]}

Return JSON: {{"label": "supported/contradicted/unverifiable"}}"""
        else:
            # –î–ª—è RAG —Ä–µ–∂–∏–º–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ –∑–æ–ª–æ—Ç–æ–º—É –æ—Ç–≤–µ—Ç—É + –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
            context_str = ""
            if context and isinstance(context, list):
                texts = []
                for ctx in context[:2]:
                    if isinstance(ctx, dict):
                        texts.append(ctx.get('text', '')[:150])
                    else:
                        texts.append(str(ctx)[:150])
                context_str = "\n".join(texts)
            
            prompt = f"""Judge if this claim is supported by reference OR context.

Claim: {claim}
Reference: {gold_answer[:300]}
Context: {context_str[:300]}

Return JSON: {{"label": "supported/contradicted/unverifiable"}}"""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Judge claims. Return JSON."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0,
                max_tokens=50,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get('label', 'unverifiable')
            
        except Exception:
            return 'unverifiable'
    
    def analyze_question(self, q_data: dict) -> dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º hallucination –¥–ª—è –æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
        
        q_id = q_data['question_id']
        category = q_data['category']
        gold_answer = q_data['gold_answer']
        
        metrics = {}
        
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            if mode not in q_data:
                continue
            
            mode_data = q_data[mode]
            answer = mode_data.get('answer', '')
            context = mode_data.get('context_used', [])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º claims
            claims = self.extract_claims(answer, q_id, mode)
            
            if not claims:
                metrics[mode] = {
                    'total_claims': 0,
                    'HR': 0,
                    'supported': 0,
                    'contradicted': 0,
                    'unverifiable': 0
                }
                continue
            
            # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π claim
            labels = []
            for claim_obj in claims:
                claim_text = claim_obj.get('text', str(claim_obj))
                label = self.judge_claim(claim_text, gold_answer, context, mode)
                labels.append(label)
            
            # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
            total = len(labels)
            supported = labels.count('supported')
            contradicted = labels.count('contradicted')
            unverifiable = labels.count('unverifiable')
            
            hr = (contradicted + unverifiable) / total if total > 0 else 0
            
            metrics[mode] = {
                'total_claims': total,
                'HR': round(hr, 3),
                'supported': supported,
                'contradicted': contradicted,
                'unverifiable': unverifiable
            }
        
        return {
            'question_id': q_id,
            'category': category,
            'metrics': metrics
        }
    
    def run_analysis(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ –Ω–∞ –≤—Å–µ—Ö 706 –≤–æ–ø—Ä–æ—Å–∞—Ö"""
        
        print("\n" + "="*80)
        print("üî¨ –ê–ù–ê–õ–ò–ó HALLUCINATION –ù–ê –ü–û–õ–ù–û–ú –î–ê–¢–ê–°–ï–¢–ï (706 –≤–æ–ø—Ä–æ—Å–æ–≤)")
        print("="*80)
        
        start_time = datetime.now()
        
        # –ë–µ—Ä—ë–º sample –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ (–∫–∞–∂–¥—ã–π 7-–π –≤–æ–ø—Ä–æ—Å = ~100 –≤–æ–ø—Ä–æ—Å–æ–≤)
        sample_indices = list(range(0, len(self.full_results['results']), 7))
        sample_questions = [self.full_results['results'][i] for i in sample_indices]
        
        print(f"\nüìä –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—É—é –≤—ã–±–æ—Ä–∫—É: {len(sample_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        for i, q_data in enumerate(sample_questions, 1):
            if i % 20 == 1:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/{len(sample_questions)}")
            
            result = self.analyze_question(q_data)
            self.hallucination_metrics.append(result)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.print_full_analysis()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        self.save_results()
        
        elapsed = (datetime.now() - start_time).total_seconds()
        print(f"\n‚è±Ô∏è –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω –∑–∞ {elapsed/60:.1f} –º–∏–Ω—É—Ç")
    
    def print_full_analysis(self):
        """–í—ã–≤–æ–¥–∏–º –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
        
        print("\n" + "="*80)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê HALLUCINATION (–ü–û–õ–ù–´–ô –î–ê–¢–ê–°–ï–¢)")
        print("="*80)
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        method_metrics = {
            'base_llm': {'HR': [], 'supported': [], 'contradicted': [], 'unverifiable': []},
            'vector_rag': {'HR': [], 'supported': [], 'contradicted': [], 'unverifiable': []},
            'graph_rag': {'HR': [], 'supported': [], 'contradicted': [], 'unverifiable': []},
            'hybrid_ahs': {'HR': [], 'supported': [], 'contradicted': [], 'unverifiable': []}
        }
        
        category_metrics = {}
        
        for result in self.hallucination_metrics:
            category = result['category']
            if category not in category_metrics:
                category_metrics[category] = {
                    'base_llm': [], 'vector_rag': [], 
                    'graph_rag': [], 'hybrid_ahs': []
                }
            
            for mode, metrics in result['metrics'].items():
                if metrics['total_claims'] > 0:
                    method_metrics[mode]['HR'].append(metrics['HR'])
                    support_rate = metrics['supported'] / metrics['total_claims']
                    method_metrics[mode]['supported'].append(support_rate)
                    method_metrics[mode]['contradicted'].append(metrics['contradicted'] / metrics['total_claims'])
                    method_metrics[mode]['unverifiable'].append(metrics['unverifiable'] / metrics['total_claims'])
                    category_metrics[category][mode].append(metrics['HR'])
        
        # 1. –ì–õ–ê–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´
        print("\nüèÜ –ì–õ–ê–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ (Hallucination Rate):")
        print("-"*60)
        
        avg_results = {}
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            if method_metrics[mode]['HR']:
                avg_hr = np.mean(method_metrics[mode]['HR']) * 100
                avg_support = np.mean(method_metrics[mode]['supported']) * 100
                avg_contra = np.mean(method_metrics[mode]['contradicted']) * 100
                avg_unver = np.mean(method_metrics[mode]['unverifiable']) * 100
                
                avg_results[mode] = avg_hr
                
                print(f"\n{mode.upper()}:")
                print(f"  üìâ Hallucination Rate: {avg_hr:.1f}%")
                print(f"  ‚úÖ Support Rate: {avg_support:.1f}%")
                print(f"  ‚ùå Contradicted: {avg_contra:.1f}%")
                print(f"  ‚ùì Unverifiable: {avg_unver:.1f}%")
        
        # 2. –†–ï–ô–¢–ò–ù–ì –ú–ï–¢–û–î–û–í
        print("\nü•á –†–ï–ô–¢–ò–ù–ì –ú–ï–¢–û–î–û–í (–º–µ–Ω—å—à–µ HR = –ª—É—á—à–µ):")
        print("-"*60)
        sorted_methods = sorted(avg_results.items(), key=lambda x: x[1])
        
        for i, (mode, hr) in enumerate(sorted_methods, 1):
            emoji = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else "4Ô∏è‚É£"
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ base_llm
            improvement = ""
            if mode != 'base_llm' and 'base_llm' in avg_results:
                reduction = (avg_results['base_llm'] - hr) / avg_results['base_llm'] * 100
                improvement = f" (‚Üì{reduction:.0f}% vs base)"
            
            print(f"{emoji} {mode:12}: HR = {hr:.1f}%{improvement}")
        
        # 3. –ê–ù–ê–õ–ò–ó –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú
        print("\nüìà –°–ü–ï–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        print("-"*60)
        
        for category in sorted(category_metrics.keys()):
            print(f"\n{category.upper()} ({len([r for r in self.hallucination_metrics if r['category'] == category])} –≤–æ–ø—Ä–æ—Å–æ–≤):")
            
            cat_results = {}
            for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
                if category_metrics[category][mode]:
                    avg_hr = np.mean(category_metrics[category][mode]) * 100
                    cat_results[mode] = avg_hr
                    print(f"  {mode:12}: {avg_hr:.1f}%")
            
            if cat_results:
                best_mode = min(cat_results, key=cat_results.get)
                print(f"  ‚≠ê –õ—É—á—à–∏–π: {best_mode}")
        
        # 4. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨
        print("\nüìä –£–õ–£–ß–®–ï–ù–ò–ï –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û BASE_LLM:")
        print("-"*60)
        
        base_hr = avg_results.get('base_llm', 100)
        for mode in ['vector_rag', 'graph_rag', 'hybrid_ahs']:
            if mode in avg_results:
                improvement = (base_hr - avg_results[mode]) / base_hr * 100
                print(f"{mode:12}: —Å–Ω–∏–∂–µ–Ω–∏–µ HR –Ω–∞ {improvement:.1f}%")
        
        # 5. –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´
        print("\n‚úÖ –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –î–õ–Ø –ù–ê–£–ß–ù–û–ô –°–¢–ê–¢–¨–ò:")
        print("-"*60)
        
        best_method = sorted_methods[0][0]
        best_hr = sorted_methods[0][1]
        
        print(f"\n1. –õ–£–ß–®–ò–ô –ú–ï–¢–û–î: {best_method.upper()} —Å HR = {best_hr:.1f}%")
        
        if 'base_llm' in avg_results:
            print(f"\n2. –ë–ï–ó –ö–û–ù–¢–ï–ö–°–¢–ê: base_llm –ø–æ–∫–∞–∑–∞–ª HR = {avg_results['base_llm']:.1f}%")
            print(f"   ‚Üí –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        if 'vector_rag' in avg_results:
            reduction = (avg_results.get('base_llm', 100) - avg_results['vector_rag']) / avg_results.get('base_llm', 100) * 100
            print(f"\n3. WEB-AUGMENTED GENERATION: —Å–Ω–∏–∂–∞–µ—Ç HR –Ω–∞ {reduction:.0f}%")
            print(f"   ‚Üí –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        if 'hybrid_ahs' in avg_results:
            print(f"\n4. –ì–ò–ë–†–ò–î–ù–´–ô –ü–û–î–•–û–î: HR = {avg_results['hybrid_ahs']:.1f}%")
            hybrid_rank = [i for i, (m, _) in enumerate(sorted_methods, 1) if m == 'hybrid_ahs'][0]
            if hybrid_rank <= 2:
                print(f"   ‚Üí –ó–∞–Ω—è–ª {hybrid_rank} –º–µ—Å—Ç–æ, –ø–æ–∫–∞–∑–∞–≤ —Ö–æ—Ä–æ—à—É—é —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç—å")
            else:
                print(f"   ‚Üí –ù–µ –æ–ø—Ä–∞–≤–¥–∞–ª –æ–∂–∏–¥–∞–Ω–∏–π (–º–µ—Å—Ç–æ {hybrid_rank})")
        
        print("\n5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å", best_method.upper())
        print(f"   ‚Üí –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –Ω–∞–∏–º–µ–Ω—å—à–∏–π —É—Ä–æ–≤–µ–Ω—å –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π")
    
    def save_results(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'hallucination_FULL_706_analysis_{timestamp}.json'
        
        output = {
            'dataset_size': 706,
            'sample_size': len(self.hallucination_metrics),
            'timestamp': datetime.now().isoformat(),
            'results': self.hallucination_metrics
        }
        
        with open(filename, 'w') as f:
            json.dump(output, f, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

def main():
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑ hallucination –Ω–∞ –ü–û–õ–ù–û–ú –¥–∞—Ç–∞—Å–µ—Ç–µ...")
    analyzer = FullDatasetHallucinationAnalyzer()
    analyzer.run_analysis()
    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù!")

if __name__ == "__main__":
    main()