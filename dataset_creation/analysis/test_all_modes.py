#!/usr/bin/env python3
"""
–¢–ï–°–¢ –í–°–ï–• 4 –†–ï–ñ–ò–ú–û–í –Ω–∞ 5 –≤–æ–ø—Ä–æ—Å–∞—Ö
–£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–∞–∂–¥—ã–π —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∏ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –¥—Ä—É–≥–∏—Ö
"""

import json
import requests
import numpy as np
from pathlib import Path
from typing import Dict, List
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

class TestAllModes:
    def __init__(self):
        self.openai_key = os.getenv('OPENAI_API_KEY')
        self.tavily_key = "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"
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º 5 —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        self.test_questions = self.load_test_questions()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–æ–≤
        self.results = {
            'base_llm': [],
            'vector_rag': [],
            'graph_rag': [],
            'hybrid_ahs': []
        }
    
    def load_test_questions(self) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∂–∞–µ–º 5 –≤–æ–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        with open("../data/apqc_auto.json", 'r') as f:
            data = json.load(f)
        
        # –ë–µ—Ä—ë–º –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        test_q = []
        categories_needed = ['causal', 'diagnostic', 'factual', 'comparative']
        
        for cat in categories_needed:
            for q in data['questions']:
                if q['category'] == cat and len(test_q) < 5:
                    test_q.append(q)
                    break
        
        # –î–æ–±–∞–≤–∏–º –µ—â—ë –æ–¥–∏–Ω causal
        for q in data['questions']:
            if q['category'] == 'causal' and q not in test_q:
                test_q.append(q)
                break
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(test_q)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:")
        for i, q in enumerate(test_q, 1):
            print(f"  {i}. [{q['category']}] {q['question'][:50]}...")
        
        return test_q[:5]
    
    def test_base_llm(self, question: str) -> Dict:
        """–¢–µ—Å—Ç 1: –ë–∞–∑–æ–≤—ã–π LLM –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        from openai import OpenAI
        client = OpenAI(api_key=self.openai_key)
        
        try:
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an automotive expert. Answer concisely."},
                    {"role": "user", "content": question}
                ],
                temperature=0.0,
                max_tokens=200
            )
            
            answer = response.choices[0].message.content
            
            return {
                'mode': 'base_llm',
                'answer': answer,
                'context_used': None,
                'context_length': 0
            }
        except Exception as e:
            print(f"Error in base_llm: {e}")
            return {'mode': 'base_llm', 'answer': 'Error', 'context_used': None, 'context_length': 0}
    
    def get_mock_vector_retrieval(self, question: str) -> List[str]:
        """–ú–æ–∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –±–∞–∑—ã"""
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–º—É–ª—è—Ü–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
        mock_contexts = {
            'brake': [
                "Brake pads should be replaced when they reach 3-4mm thickness.",
                "Squealing brakes often indicate worn pads or glazed rotors."
            ],
            'engine': [
                "Engine knocking can be caused by low octane fuel or carbon deposits.",
                "Regular oil changes prevent engine wear and extend engine life."
            ],
            'transmission': [
                "Transmission fluid should be changed every 30,000-60,000 miles.",
                "Slipping gears indicate low fluid or worn clutch plates."
            ]
        }
        
        # –ò—â–µ–º –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
        question_lower = question.lower()
        for key, contexts in mock_contexts.items():
            if key in question_lower:
                return contexts
        
        # –î–µ—Ñ–æ–ª—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        return ["Regular maintenance is key to vehicle longevity."]
    
    def get_mock_graph_retrieval(self, question: str, category: str) -> List[str]:
        """–ú–æ–∫ –≥—Ä–∞—Ñ–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞ —Å —É—á—ë—Ç–æ–º —Å–≤—è–∑–µ–π"""
        
        # –≠–º—É–ª—è—Ü–∏—è –≥—Ä–∞—Ñ–æ–≤—ã—Ö —Å–≤—è–∑–µ–π
        if category == 'causal':
            return [
                "Component A causes issue B due to mechanical interaction.",
                "Root cause analysis shows correlation between symptoms."
            ]
        elif category == 'diagnostic':
            return [
                "Diagnostic procedure: 1) Check codes 2) Test components 3) Verify fix.",
                "Common symptoms indicate specific component failures."
            ]
        else:
            return self.get_mock_vector_retrieval(question)
    
    def test_vector_rag(self, question: str) -> Dict:
        """–¢–µ—Å—Ç 2: –í–µ–∫—Ç–æ—Ä–Ω—ã–π RAG"""
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫
        contexts = self.get_mock_vector_retrieval(question)
        context_str = "\n".join(contexts)
        
        from openai import OpenAI
        client = OpenAI(api_key=self.openai_key)
        
        try:
            prompt = f"Context:\n{context_str}\n\nQuestion: {question}\nAnswer based on context:"
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Answer based on the provided context."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=200
            )
            
            answer = response.choices[0].message.content
            
            return {
                'mode': 'vector_rag',
                'answer': answer,
                'context_used': contexts,
                'context_length': len(context_str)
            }
        except Exception as e:
            print(f"Error in vector_rag: {e}")
            return {'mode': 'vector_rag', 'answer': 'Error', 'context_used': contexts, 'context_length': 0}
    
    def test_graph_rag(self, question: str, category: str) -> Dict:
        """–¢–µ—Å—Ç 3: –ì—Ä–∞—Ñ–æ–≤—ã–π RAG"""
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ
        contexts = self.get_mock_graph_retrieval(question, category)
        context_str = "\n".join(contexts)
        
        from openai import OpenAI
        client = OpenAI(api_key=self.openai_key)
        
        try:
            prompt = f"Graph context:\n{context_str}\n\nQuestion: {question}\nAnswer using causal relationships:"
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Answer based on graph relationships in context."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=200
            )
            
            answer = response.choices[0].message.content
            
            return {
                'mode': 'graph_rag',
                'answer': answer,
                'context_used': contexts,
                'context_length': len(context_str)
            }
        except Exception as e:
            print(f"Error in graph_rag: {e}")
            return {'mode': 'graph_rag', 'answer': 'Error', 'context_used': contexts, 'context_length': 0}
    
    def test_hybrid_ahs(self, question: str, category: str) -> Dict:
        """–¢–µ—Å—Ç 4: –ì–∏–±—Ä–∏–¥–Ω—ã–π —Ä–µ–∂–∏–º"""
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤–µ–∫—Ç–æ—Ä–Ω—ã–π –∏ –≥—Ä–∞—Ñ–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        vector_contexts = self.get_mock_vector_retrieval(question)
        graph_contexts = self.get_mock_graph_retrieval(question, category)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤–µ—Å–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        weights = {
            'causal': {'graph': 0.7, 'vector': 0.3},
            'diagnostic': {'graph': 0.7, 'vector': 0.3},
            'factual': {'graph': 0.3, 'vector': 0.7},
            'comparative': {'graph': 0.4, 'vector': 0.6}
        }
        
        w = weights.get(category, {'graph': 0.5, 'vector': 0.5})
        
        # –°–º–µ—à–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã —Å —É—á—ë—Ç–æ–º –≤–µ—Å–æ–≤
        if w['vector'] > w['graph']:
            contexts = vector_contexts + graph_contexts[:1]
        else:
            contexts = graph_contexts + vector_contexts[:1]
        
        context_str = "\n".join(contexts)
        
        from openai import OpenAI
        client = OpenAI(api_key=self.openai_key)
        
        try:
            prompt = f"Hybrid context (vector+graph):\n{context_str}\n\nQuestion: {question}\nAnswer comprehensively:"
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Answer using both factual and relational context."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=200
            )
            
            answer = response.choices[0].message.content
            
            return {
                'mode': 'hybrid_ahs',
                'answer': answer,
                'context_used': contexts,
                'context_length': len(context_str)
            }
        except Exception as e:
            print(f"Error in hybrid_ahs: {e}")
            return {'mode': 'hybrid_ahs', 'answer': 'Error', 'context_used': contexts, 'context_length': 0}
    
    def run_all_tests(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ 4 —Ä–µ–∂–∏–º–∞ –Ω–∞ 5 –≤–æ–ø—Ä–æ—Å–∞—Ö"""
        
        print("\n" + "="*80)
        print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–°–ï–• 4 –†–ï–ñ–ò–ú–û–í")
        print("="*80)
        
        for i, q in enumerate(self.test_questions, 1):
            print(f"\nüìù –í–æ–ø—Ä–æ—Å {i}/{len(self.test_questions)}: {q['question'][:100]}...")
            print(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {q['category']}")
            print("-"*80)
            
            # –¢–µ—Å—Ç 1: base_llm
            print("  ü§ñ Testing base_llm...")
            result_base = self.test_base_llm(q['question'])
            self.results['base_llm'].append(result_base)
            print(f"     ‚úì Answer length: {len(result_base['answer'])} chars")
            
            # –¢–µ—Å—Ç 2: vector_rag
            print("  üìä Testing vector_rag...")
            result_vector = self.test_vector_rag(q['question'])
            self.results['vector_rag'].append(result_vector)
            print(f"     ‚úì Context used: {result_vector['context_length']} chars")
            
            # –¢–µ—Å—Ç 3: graph_rag
            print("  üï∏Ô∏è Testing graph_rag...")
            result_graph = self.test_graph_rag(q['question'], q['category'])
            self.results['graph_rag'].append(result_graph)
            print(f"     ‚úì Graph context: {result_graph['context_length']} chars")
            
            # –¢–µ—Å—Ç 4: hybrid_ahs
            print("  üîÑ Testing hybrid_ahs...")
            result_hybrid = self.test_hybrid_ahs(q['question'], q['category'])
            self.results['hybrid_ahs'].append(result_hybrid)
            print(f"     ‚úì Hybrid context: {result_hybrid['context_length']} chars")
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤
            print("\n  üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤:")
            print(f"     Base LLM: {result_base['answer'][:100]}...")
            print(f"     Vector RAG: {result_vector['answer'][:100]}...")
            print(f"     Graph RAG: {result_graph['answer'][:100]}...")
            print(f"     Hybrid: {result_hybrid['answer'][:100]}...")
    
    def verify_differences(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Ä–µ–∂–∏–º—ã –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è"""
        
        print("\n" + "="*80)
        print("–í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø –†–ê–ó–õ–ò–ß–ò–ô –ú–ï–ñ–î–£ –†–ï–ñ–ò–ú–ê–ú–ò")
        print("="*80)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç?
        print("\n1Ô∏è‚É£ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:")
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            avg_context = np.mean([r.get('context_length', 0) for r in self.results[mode]])
            print(f"   {mode}: {avg_context:.0f} —Å–∏–º–≤–æ–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –†–∞–∑–ª–∏—á–∞—é—Ç—Å—è –ª–∏ –æ—Ç–≤–µ—Ç—ã?
        print("\n2Ô∏è‚É£ –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–æ–≤:")
        for i in range(len(self.test_questions)):
            answers = {
                'base_llm': self.results['base_llm'][i]['answer'],
                'vector_rag': self.results['vector_rag'][i]['answer'],
                'graph_rag': self.results['graph_rag'][i]['answer'],
                'hybrid_ahs': self.results['hybrid_ahs'][i]['answer']
            }
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ø–∞—Ä–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            unique_answers = len(set(answers.values()))
            print(f"   –í–æ–ø—Ä–æ—Å {i+1}: {unique_answers}/4 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –†–∞–±–æ—Ç–∞—é—Ç –ª–∏ –≤—Å–µ —Ä–µ–∂–∏–º—ã?
        print("\n3Ô∏è‚É£ –°—Ç–∞—Ç—É—Å —Ä–∞–±–æ—Ç—ã:")
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            errors = sum(1 for r in self.results[mode] if r['answer'] == 'Error')
            if errors == 0:
                print(f"   ‚úÖ {mode}: –†–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
            else:
                print(f"   ‚ùå {mode}: {errors} –æ—à–∏–±–æ–∫")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        with open("test_all_modes_results.json", 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print("\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ test_all_modes_results.json")

def main():
    tester = TestAllModes()
    tester.run_all_tests()
    tester.verify_differences()
    
    print("\n" + "="*80)
    print("–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï")
    print("="*80)
    print("‚úÖ –í—Å–µ 4 —Ä–µ–∂–∏–º–∞ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω—ã")
    print("üìä –ü—Ä–æ–≤–µ—Ä—å—Ç–µ test_all_modes_results.json –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")

if __name__ == "__main__":
    main()