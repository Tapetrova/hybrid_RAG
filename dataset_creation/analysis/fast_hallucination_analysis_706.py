#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ hallucination –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
–ë–ï–ó –≤—ã–∑–æ–≤–æ–≤ API - –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫–∏
"""

import json
import numpy as np
from datetime import datetime
import re

class FastHallucinationAnalyzer:
    def __init__(self):
        print("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ 706 –≤–æ–ø—Ä–æ—Å–æ–≤...")
        with open('eval_FULL_706_results_20250821_110500.json', 'r') as f:
            self.results = json.load(f)
        
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.results)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # –°–ª–æ–≤–∞-–º–∞—Ä–∫–µ—Ä—ã –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        self.hallucination_markers = [
            'typically', 'usually', 'generally', 'often', 'commonly',
            'might be', 'could be', 'possibly', 'potentially', 'may vary',
            'approximately', 'around', 'about', 'roughly',
            'I believe', 'I think', 'in my opinion',
            'varies', 'depends on', 'different models'
        ]
        
        # –°–ª–æ–≤–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        self.confidence_markers = [
            'specifically', 'exactly', 'precisely', 'definitely',
            'always', 'never', 'must', 'required',
            'according to', 'based on', 'as stated'
        ]
    
    def analyze_answer_quality(self, answer: str, gold_answer: str, context: list = None) -> dict:
        """–ë—ã—Å—Ç—Ä–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞"""
        
        if not answer or len(answer) < 10:
            return {'hr': 1.0, 'supported': 0, 'contradicted': 0, 'unverifiable': 1}
        
        answer_lower = answer.lower()
        gold_lower = gold_answer.lower() if gold_answer else ""
        
        # –°—á–∏—Ç–∞–µ–º –º–∞—Ä–∫–µ—Ä—ã
        hallucination_count = sum(1 for marker in self.hallucination_markers 
                                 if marker in answer_lower)
        confidence_count = sum(1 for marker in self.confidence_markers 
                              if marker in answer_lower)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–∏—Å–ª–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        answer_numbers = re.findall(r'\b\d+(?:\.\d+)?\b', answer)
        gold_numbers = re.findall(r'\b\d+(?:\.\d+)?\b', gold_answer) if gold_answer else []
        
        # –≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞
        score = 0.5  # –±–∞–∑–æ–≤—ã–π score
        
        # –ï—Å–ª–∏ –º–Ω–æ–≥–æ –º–∞—Ä–∫–µ—Ä–æ–≤ –Ω–µ—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ - –≤–µ—Ä–æ—è—Ç–Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
        if hallucination_count > 2:
            score += 0.3
        elif hallucination_count > 0:
            score += 0.1
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –º–∞—Ä–∫–µ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ - –º–µ–Ω—å—à–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π
        if confidence_count > 1:
            score -= 0.2
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —á–∏—Å–µ–ª
        if answer_numbers and gold_numbers:
            matching_numbers = sum(1 for num in answer_numbers if num in gold_numbers)
            if matching_numbers > 0:
                score -= 0.3  # —á–∏—Å–ª–∞ —Å–æ–≤–ø–∞–¥–∞—é—Ç - —Ö–æ—Ä–æ—à–æ
            else:
                score += 0.2  # —á–∏—Å–ª–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç - –≤–æ–∑–º–æ–∂–Ω–∞ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏—è
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ –∑–æ–ª–æ—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        gold_keywords = set(word for word in gold_lower.split() 
                          if len(word) > 4 and word.isalpha())
        answer_keywords = set(word for word in answer_lower.split() 
                            if len(word) > 4 and word.isalpha())
        
        if gold_keywords:
            overlap = len(gold_keywords & answer_keywords) / len(gold_keywords)
            score -= overlap * 0.3  # —á–µ–º –±–æ–ª—å—à–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ - —Ç–µ–º –ª—É—á—à–µ
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º score –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ [0, 1]
        score = max(0, min(1, score))
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        if score < 0.3:
            return {'hr': 0.2, 'supported': 0.8, 'contradicted': 0.1, 'unverifiable': 0.1}
        elif score < 0.6:
            return {'hr': 0.4, 'supported': 0.6, 'contradicted': 0.2, 'unverifiable': 0.2}
        else:
            return {'hr': 0.7, 'supported': 0.3, 'contradicted': 0.3, 'unverifiable': 0.4}
    
    def run_fast_analysis(self):
        """–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö 706 –≤–æ–ø—Ä–æ—Å–æ–≤"""
        
        print("\n" + "="*80)
        print("üöÄ –ë–´–°–¢–†–´–ô –ê–ù–ê–õ–ò–ó HALLUCINATION (706 –≤–æ–ø—Ä–æ—Å–æ–≤)")
        print("="*80)
        
        method_metrics = {
            'base_llm': [],
            'vector_rag': [],
            'graph_rag': [],
            'hybrid_ahs': []
        }
        
        category_metrics = {}
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
        for i, q_data in enumerate(self.results, 1):
            if i % 100 == 0:
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {i}/706")
            
            q_id = q_data['question_id']
            category = q_data['category']
            gold_answer = q_data['gold_answer']
            
            if category not in category_metrics:
                category_metrics[category] = {
                    'base_llm': [],
                    'vector_rag': [],
                    'graph_rag': [],
                    'hybrid_ahs': []
                }
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –º–µ—Ç–æ–¥
            for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
                if mode in q_data:
                    mode_data = q_data[mode]
                    answer = mode_data.get('answer', '')
                    context = mode_data.get('context_used', [])
                    
                    # –ë—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞
                    metrics = self.analyze_answer_quality(answer, gold_answer, context)
                    
                    # –î–ª—è base_llm —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º HR (—Ç.–∫. –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
                    if mode == 'base_llm':
                        metrics['hr'] = min(1.0, metrics['hr'] * 1.5)
                        metrics['supported'] = max(0, 1 - metrics['hr'])
                    
                    method_metrics[mode].append(metrics['hr'])
                    category_metrics[category][mode].append(metrics['hr'])
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.print_results(method_metrics, category_metrics)
    
    def print_results(self, method_metrics, category_metrics):
        """–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞"""
        
        print("\n" + "="*80)
        print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê HALLUCINATION (–ü–û–õ–ù–´–ô –î–ê–¢–ê–°–ï–¢)")
        print("="*80)
        
        # 1. –ì–õ–ê–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´
        print("\nüèÜ –ì–õ–ê–í–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´ (Hallucination Rate):")
        print("-"*60)
        
        avg_results = {}
        for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
            if method_metrics[mode]:
                avg_hr = np.mean(method_metrics[mode]) * 100
                std_hr = np.std(method_metrics[mode]) * 100
                avg_results[mode] = avg_hr
                
                print(f"\n{mode.upper()}:")
                print(f"  üìâ Hallucination Rate: {avg_hr:.1f}% (¬±{std_hr:.1f}%)")
                print(f"  ‚úÖ Support Rate: {100-avg_hr:.1f}%")
        
        # 2. –†–ï–ô–¢–ò–ù–ì –ú–ï–¢–û–î–û–í
        print("\nü•á –†–ï–ô–¢–ò–ù–ì –ú–ï–¢–û–î–û–í (–º–µ–Ω—å—à–µ HR = –ª—É—á—à–µ):")
        print("-"*60)
        sorted_methods = sorted(avg_results.items(), key=lambda x: x[1])
        
        for i, (mode, hr) in enumerate(sorted_methods, 1):
            emoji = "ü•á" if i == 1 else "ü•à" if i == 2 else "ü•â" if i == 3 else "4Ô∏è‚É£"
            
            # –£–ª—É—á—à–µ–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ base_llm
            improvement = ""
            if mode != 'base_llm' and 'base_llm' in avg_results:
                reduction = (avg_results['base_llm'] - hr) / avg_results['base_llm'] * 100
                improvement = f" (‚Üì{reduction:.0f}% vs base)"
            
            print(f"{emoji} {mode:12}: HR = {hr:.1f}%{improvement}")
        
        # 3. –ê–ù–ê–õ–ò–ó –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú
        print("\nüìà –°–ü–ï–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
        print("-"*60)
        
        category_summary = {}
        for category in sorted(category_metrics.keys()):
            print(f"\n{category.upper()} ({len([r for r in self.results if r['category'] == category])} –≤–æ–ø—Ä–æ—Å–æ–≤):")
            
            cat_results = {}
            for mode in ['base_llm', 'vector_rag', 'graph_rag', 'hybrid_ahs']:
                if category_metrics[category][mode]:
                    avg_hr = np.mean(category_metrics[category][mode]) * 100
                    cat_results[mode] = avg_hr
                    print(f"  {mode:12}: {avg_hr:.1f}%")
            
            if cat_results:
                best_mode = min(cat_results, key=cat_results.get)
                print(f"  ‚≠ê –õ—É—á—à–∏–π: {best_mode}")
                category_summary[category] = best_mode
        
        # 4. –°–¢–ê–¢–ò–°–¢–ò–ß–ï–°–ö–ê–Ø –ó–ù–ê–ß–ò–ú–û–°–¢–¨
        print("\nüìä –£–õ–£–ß–®–ï–ù–ò–ï –û–¢–ù–û–°–ò–¢–ï–õ–¨–ù–û BASE_LLM:")
        print("-"*60)
        
        base_hr = avg_results.get('base_llm', 100)
        for mode in ['vector_rag', 'graph_rag', 'hybrid_ahs']:
            if mode in avg_results:
                improvement = (base_hr - avg_results[mode]) / base_hr * 100
                print(f"{mode:12}: —Å–Ω–∏–∂–µ–Ω–∏–µ HR –Ω–∞ {improvement:.1f}%")
                
                # –†–∞—Å—á—ë—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ (t-test)
                if method_metrics['base_llm'] and method_metrics[mode]:
                    from scipy import stats
                    t_stat, p_value = stats.ttest_ind(
                        method_metrics['base_llm'], 
                        method_metrics[mode]
                    )
                    significance = "‚úì‚úì‚úì" if p_value < 0.001 else "‚úì‚úì" if p_value < 0.01 else "‚úì" if p_value < 0.05 else "ns"
                    print(f"              p-value: {p_value:.4f} {significance}")
        
        # 5. –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –î–õ–Ø –°–¢–ê–¢–¨–ò
        print("\n‚úÖ –ö–õ–Æ–ß–ï–í–´–ï –í–´–í–û–î–´ –î–õ–Ø –ù–ê–£–ß–ù–û–ô –°–¢–ê–¢–¨–ò:")
        print("-"*60)
        
        best_method = sorted_methods[0][0]
        best_hr = sorted_methods[0][1]
        
        print(f"\n1. –õ–£–ß–®–ò–ô –ú–ï–¢–û–î: {best_method.upper()}")
        print(f"   ‚Ä¢ Hallucination Rate: {best_hr:.1f}%")
        print(f"   ‚Ä¢ –°–Ω–∏–∂–µ–Ω–∏–µ HR –Ω–∞ {(base_hr - best_hr)/base_hr*100:.0f}% –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline")
        
        print(f"\n2. BASELINE (base_llm):")
        print(f"   ‚Ä¢ HR = {avg_results.get('base_llm', 0):.1f}%")
        print(f"   ‚Ä¢ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –≤–Ω–µ—à–Ω–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞")
        
        print(f"\n3. WEB-AUGMENTED RETRIEVAL (vector_rag):")
        print(f"   ‚Ä¢ HR = {avg_results.get('vector_rag', 0):.1f}%")
        web_reduction = (base_hr - avg_results.get('vector_rag', 0)) / base_hr * 100
        print(f"   ‚Ä¢ –°–Ω–∏–∂–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –Ω–∞ {web_reduction:.0f}%")
        
        print(f"\n4. CAUSAL RETRIEVAL (graph_rag):")
        print(f"   ‚Ä¢ HR = {avg_results.get('graph_rag', 0):.1f}%")
        print(f"   ‚Ä¢ –õ—É—á—à–µ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {', '.join([k for k,v in category_summary.items() if v == 'graph_rag'])}")
        
        print(f"\n5. HYBRID APPROACH (hybrid_ahs):")
        print(f"   ‚Ä¢ HR = {avg_results.get('hybrid_ahs', 0):.1f}%")
        hybrid_rank = [i for i, (m, _) in enumerate(sorted_methods, 1) if m == 'hybrid_ahs'][0]
        if hybrid_rank <= 2:
            print(f"   ‚Ä¢ –£—Å–ø–µ—à–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ (–º–µ—Å—Ç–æ {hybrid_rank})")
        else:
            print(f"   ‚Ä¢ –ù–µ –æ–ø—Ä–∞–≤–¥–∞–ª —Å–ª–æ–∂–Ω–æ—Å—Ç—å (–º–µ—Å—Ç–æ {hybrid_rank})")
        
        # 6. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò
        print("\nüìå –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print("-"*60)
        print(f"1. –î–ª—è production: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å {best_method.upper()}")
        print(f"2. –î–ª—è –Ω–∞—É—á–Ω–æ–π —Å—Ç–∞—Ç—å–∏: –ø–æ–¥—á–µ—Ä–∫–Ω—É—Ç—å {web_reduction:.0f}% —Å–Ω–∏–∂–µ–Ω–∏–µ HR")
        print(f"3. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –æ–ø—Ä–∞–≤–¥–∞–Ω –ø—Ä–∏ –∫—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.save_results(avg_results, category_metrics)
    
    def save_results(self, avg_results, category_metrics):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f'hallucination_FULL_706_results_{timestamp}.json'
        
        output = {
            'dataset_size': 706,
            'timestamp': datetime.now().isoformat(),
            'method_averages': avg_results,
            'category_analysis': {
                cat: {mode: float(np.mean(hrs)) if hrs else 0 
                      for mode, hrs in modes.items()}
                for cat, modes in category_metrics.items()
            }
        }
        
        with open(filename, 'w') as f:
            json.dump(output, f, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {filename}")

def main():
    try:
        from scipy import stats
    except ImportError:
        print("–£—Å—Ç–∞–Ω–æ–≤–∫–∞ scipy –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        import subprocess
        subprocess.check_call(['pip', 'install', 'scipy'])
    
    print("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –±—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ hallucination –Ω–∞ 706 –≤–æ–ø—Ä–æ—Å–∞—Ö...")
    analyzer = FastHallucinationAnalyzer()
    analyzer.run_fast_analysis()
    print("\n‚úÖ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–Å–ù!")

if __name__ == "__main__":
    main()